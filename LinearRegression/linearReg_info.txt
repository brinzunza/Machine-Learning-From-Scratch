Linear Regression

- Supervised Machine-Learning Algorithm that copmutes linear relationship between the dependent variable and one or more independent variables.
    - Learns from labelled data
- Classification model for discrete or categorical data
- Regression model that can output continuous variables

Goal of Linear Regression:
- Find best fit line, implying that the error between the predicted the predicted and actual values is kept to a minimum.
- Best fit line will have the last error

Aspects
- Hypothesis function: y = a + bx
    - y are the predicted values
    - x are the input independent training data
    - a is the intercept
    - b is the coefficient of x
    - To get best line, we modify a and b 
    - When finished, the model will predict y given the input x
- Cost function: Mean Squared Error (MSE) = 1/n(sum((predicted_value - true_value)^2))
    - Cost function MSE calculates the average of the squared errors between the predicted values and the true values. 

Logic 
- a hypothesis function for current model predictions
- from existing dataset, create a loss function to evaluate current performance (starter linear function can be 0, 0 for a, b respectively)
- compute gradient descent and adjust model parameters based on learning rate and iterations
- update parameters based on results from gradient descent